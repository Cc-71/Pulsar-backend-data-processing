#include <iostream>
#include <thread>
#include <queue>
#include <mutex>
#include <condition_variable>
#include <cstring>
#include <boost/asio.hpp>
#include <fitsio.h>
#include <chrono>
#include <iomanip>
#include <filesystem>
#include <complex>
#include <memory>
#include <atomic>
#include <vector>
#include <map>
#include <sys/socket.h>
#include <netinet/in.h>
#include <fcntl.h>
#include <unistd.h>
#include <errno.h>
#include <cuda_runtime.h>
#include "cuda_fft.h"
#include <string>
#include <sstream>
#include <fstream>
#include <regex>
#include <cstdlib>
#include <deque>
#include <array>

namespace fs = std::filesystem;
using namespace boost::asio;
using namespace std::chrono;

extern bool initialize_multi_gpu_system();
extern void print_multi_gpu_stats();
extern int get_available_gpu_count();

const int PORT = 60524;
const int BUFFER_SIZE = 4104;  //UDPæ•°æ®åŒ…ç¼“å†²åŒºå¤§å°
static const size_t PACKET_PAYLOAD_SIZE = 4096;
static const size_t PACKET_HEADER_SIZE = 8;
const int PACKETS_PER_CHUNK = 16 * 3;  // æ¯ä¸ªæ•°æ®å—åŒ…å«çš„æ•°æ®åŒ…æ•°é‡ (48ä¸ª)
const int CHUNK_SIZE = 64 * 1024 * 3; // æ¯ä¸ªæ•°æ®å—å¤§å°ï¼š192KB

// ç½‘ç»œæ¥æ”¶å‚æ•°
const int NUM_RECV_THREADS = 2;  // æ¥æ”¶çº¿ç¨‹æ•°é‡
const int BATCH_SIZE = 64;  // æ¯æ¬¡æ‰¹é‡æ¥æ”¶çš„æ•°æ®åŒ…æ•°é‡

//è®¾ç½®æ•°æ®åŒ…ç¼“å­˜å¤§å°ä¸º4MB
const size_t MAX_QUEUE_SIZE = 200000;  // æ§åˆ¶å†…å­˜ä½¿ç”¨

//è®¾ç½®CHUNKç¼“å­˜å¤§å°ä¸º4MB
static const size_t MAX_CHUNK_COUNT = 6400; //// æ•°æ®å—ç¼“å­˜æœ€å¤§æ•°é‡
static const size_t ACC_BUFFER_SIZE = MAX_CHUNK_COUNT * CHUNK_SIZE; // ç´¯ç§¯ç¼“å†²åŒºæ€»å¤§å°

const int NUM_THREADS = 4;   // æ•°æ®åŒ…è§£æçº¿ç¨‹æ•°é‡
int NUM_FFT_THREADS = 16;   // FFTå¤„ç†çº¿ç¨‹æ•°é‡ï¼ˆå¿…é¡»>4ï¼‰
int OPTIMAL_FFT_THREADS_PER_GPU = 4;  // æ¯ä¸ªGPUçš„æœ€ä½³çº¿ç¨‹æ•°

const int FFT_RESULTS_PER_SAVE = 3;  // æ¯ä¸ªæ–‡ä»¶ä¿å­˜çš„FFTç»“æœæ•°é‡

// æ‰¹é‡ä¿å­˜é…ç½®
const int BATCH_SAVE_SIZE = 10;    // æ‰¹é‡ä¿å­˜çš„FFTç»“æœæ•°é‡
const int SAVE_TIMEOUT_MS = 1000;  // ä¿å­˜è¶…æ—¶æ—¶é—´

// æ€§èƒ½ç›‘æ§ç›¸å…³
const int SAVE_STATS_INTERVAL = 5;  // æ€§èƒ½ç»Ÿè®¡è¾“å‡ºé—´éš”
std::atomic<uint64_t> saved_count{0};

// ==================== æ€§èƒ½æµ‹é‡ç»“æ„ ====================
struct PerformanceMetrics {
    // ç½‘ç»œæ¥æ”¶æ€§èƒ½
    std::atomic<uint64_t> total_received_packets{0};
    std::atomic<uint64_t> total_received_bytes{0};
    std::atomic<uint64_t> network_errors{0};
    std::atomic<uint64_t> network_timeouts{0};

    // å»¶è¿Ÿæµ‹é‡
    std::atomic<double> avg_packet_latency_us{0.0};
    std::atomic<double> avg_processing_latency_us{0.0};
    std::atomic<double> avg_fft_latency_us{0.0};
    std::atomic<double> avg_save_latency_us{0.0};

    // ååé‡æµ‹é‡
    std::atomic<double> current_receive_rate{0.0};
    std::atomic<double> peak_receive_rate{0.0};
    std::atomic<double> current_process_rate{0.0};
    std::atomic<double> peak_process_rate{0.0};

    // ç“¶é¢ˆæŒ‡æ ‡
    std::atomic<uint64_t> queue_overflows{0};
    std::atomic<uint64_t> cuda_resource_waits{0};
    std::atomic<uint64_t> file_write_errors{0};
    std::atomic<uint64_t> memory_allocation_failures{0};

     // æ–°å¢å¤šGPUç›¸å…³æŒ‡æ ‡
    std::atomic<int> active_gpu_count{0};
    std::atomic<uint64_t> total_gpu_processed{0};
    std::atomic<uint64_t> gpu_errors{0};
    std::atomic<double> gpu_utilization_avg{0.0};
    std::atomic<double> multi_gpu_speedup{1.0};

    // æ—¶é—´æˆ³
    std::chrono::steady_clock::time_point start_time;
    std::chrono::steady_clock::time_point last_update_time;

    PerformanceMetrics() {
        start_time = std::chrono::steady_clock::now();
        last_update_time = start_time;
    }

    void updateReceiveRate(double rate) {
        current_receive_rate.store(rate);
        if (rate > peak_receive_rate.load()) {
            peak_receive_rate.store(rate);
        }
    }

    void updateProcessRate(double rate) {
        current_process_rate.store(rate);
        if (rate > peak_process_rate.load()) {
            peak_process_rate.store(rate);
        }
    }

    void printSummary() {
        auto now = std::chrono::steady_clock::now();
        auto total_duration = std::chrono::duration_cast<std::chrono::seconds>(now - start_time);

        std::cout << "\nğŸ” ========== æ€§èƒ½åˆ†ææŠ¥å‘Š ========== ğŸ”" << std::endl;
        std::cout << "â±ï¸  æ€»è¿è¡Œæ—¶é—´: " << total_duration.count() << "ç§’" << std::endl;
        std::cout << "ğŸ® æ´»è·ƒGPUæ•°é‡: " << active_gpu_count.load() << std::endl;
        std::cout << "ğŸ“¦ æ€»æ¥æ”¶æ•°æ®åŒ…: " << total_received_packets.load() << std::endl;
        std::cout << "ğŸ“Š æ€»æ¥æ”¶æ•°æ®é‡: " << (total_received_bytes.load() / 1024.0 / 1024.0) << "MB" << std::endl;
        std::cout << "ğŸš€ å³°å€¼æ¥æ”¶é€Ÿç‡: " << peak_receive_rate.load() << " pkt/s" << std::endl;
        std::cout << "âš¡ å³°å€¼å¤„ç†é€Ÿç‡: " << peak_process_rate.load() << " pkt/s" << std::endl;
        std::cout << "ğŸ“ˆ å¤šGPUåŠ é€Ÿæ¯”: " << multi_gpu_speedup.load() << "x" << std::endl;
        std::cout << "ğŸ¯ GPUå¹³å‡åˆ©ç”¨ç‡: " << gpu_utilization_avg.load() << "%" << std::endl;
        std::cout << "ğŸ”§ GPUæ€»å¤„ç†é‡: " << total_gpu_processed.load() << std::endl;
        std::cout << "â° å¹³å‡æ•°æ®åŒ…å»¶è¿Ÿ: " << avg_packet_latency_us.load() << "Î¼s" << std::endl;
        std::cout << "ğŸ”§ å¹³å‡å¤„ç†å»¶è¿Ÿ: " << avg_processing_latency_us.load() << "Î¼s" << std::endl;
        std::cout << "ğŸ“ˆ å¹³å‡FFTå»¶è¿Ÿ: " << avg_fft_latency_us.load() << "Î¼s" << std::endl;
        std::cout << "ğŸ’¾ å¹³å‡ä¿å­˜å»¶è¿Ÿ: " << avg_save_latency_us.load() << "Î¼s" << std::endl;
        std::cout << "âŒ ç½‘ç»œé”™è¯¯æ¬¡æ•°: " << network_errors.load() << std::endl;
        std::cout << "âŒ GPUé”™è¯¯æ¬¡æ•°: " << gpu_errors.load() << std::endl;
        std::cout << "â³ ç½‘ç»œè¶…æ—¶æ¬¡æ•°: " << network_timeouts.load() << std::endl;
        std::cout << "ğŸš« é˜Ÿåˆ—æº¢å‡ºæ¬¡æ•°: " << queue_overflows.load() << std::endl;
        std::cout << "ğŸ¯ CUDAèµ„æºç­‰å¾…æ¬¡æ•°: " << cuda_resource_waits.load() << std::endl;
        std::cout << "ğŸ’¿ æ–‡ä»¶å†™å…¥é”™è¯¯æ¬¡æ•°: " << file_write_errors.load() << std::endl;
        std::cout << "=============================================\n" << std::endl;
    }
};

// å…¨å±€æ€§èƒ½æŒ‡æ ‡
static PerformanceMetrics g_metrics;

// ==================== CUDAåˆ©ç”¨ç‡ä¼°ç®—å™¨ ====================
class CUDAUtilizationEstimator {
private:
    std::atomic<size_t> active_kernels_{0};
    std::atomic<size_t> total_kernel_time_us_{0};
    std::chrono::steady_clock::time_point start_time_;
    std::mutex stats_mutex_;

public:
    CUDAUtilizationEstimator() : start_time_(std::chrono::steady_clock::now()) {}

    void kernelStart() {
        active_kernels_++;
    }

    void kernelEnd(size_t duration_us) {
        active_kernels_--;
        total_kernel_time_us_ += duration_us;
    }

    float getEstimatedUtilization() {
        auto now = std::chrono::steady_clock::now();
        auto wall_elapsed = std::chrono::duration_cast<std::chrono::microseconds>(now - start_time_);

        if (wall_elapsed.count() > 0) {
            float util = std::min(100.0f,
                (float)total_kernel_time_us_.load() * 100.0f / wall_elapsed.count());
            return util;
        }
        return 0.0f;
    }

    size_t getActiveKernels() const {
        return active_kernels_.load();
    }

    void reset() {
        total_kernel_time_us_ = 0;
        start_time_ = std::chrono::steady_clock::now();
    }
};

static CUDAUtilizationEstimator g_cuda_estimator;

// ==================== å»¶è¿Ÿæµ‹é‡å™¨ ====================
class LatencyTracker {
private:
    std::deque<double> samples_;
    std::mutex mutex_;
    size_t max_samples_;

public:
    LatencyTracker(size_t max_samples = 1000) : max_samples_(max_samples) {}

    void addSample(double latency_us) {
        std::lock_guard<std::mutex> lock(mutex_);
        samples_.push_back(latency_us);
        if (samples_.size() > max_samples_) {
            samples_.pop_front();
        }
    }

    double getAverageLatency() {
        std::lock_guard<std::mutex> lock(mutex_);
        if (samples_.empty()) return 0.0;
        double sum = 0.0;
        for (double sample : samples_) {
            sum += sample;
        }
        return sum / samples_.size();
    }

    double getMaxLatency() {
        std::lock_guard<std::mutex> lock(mutex_);
        if (samples_.empty()) return 0.0;
        return *std::max_element(samples_.begin(), samples_.end());
    }

    double getMinLatency() {
        std::lock_guard<std::mutex> lock(mutex_);
        if (samples_.empty()) return 0.0;
        return *std::min_element(samples_.begin(), samples_.end());
    }
};

// å…¨å±€å»¶è¿Ÿè¿½è¸ªå™¨
static LatencyTracker g_network_latency;
static LatencyTracker g_processing_latency;
static LatencyTracker g_fft_latency;
static LatencyTracker g_save_latency;

// ==================== æ•°æ®åŒ…æ•°æ®ç»“æ„ ====================
struct PacketData {
    std::vector<uint8_t> data;
    std::chrono::steady_clock::time_point timestamp;

    PacketData() = default;
    PacketData(const std::vector<uint8_t>& d)
        : data(d), timestamp(std::chrono::steady_clock::now()) {}
};

// ==================== å¸¦æ—¶é—´æˆ³çš„æ•°æ®åŒ… ====================
struct TimestampedPacket {
    std::vector<uint8_t> data;
    ip::udp::endpoint endpoint;
    std::chrono::steady_clock::time_point receive_time;
    std::chrono::steady_clock::time_point process_start_time;

    TimestampedPacket(const std::vector<uint8_t>& d, const ip::udp::endpoint& ep)
        : data(d), endpoint(ep), receive_time(std::chrono::steady_clock::now()) {}
};

// ==================== æ— é”ç¯å½¢ç¼“å†²åŒº ====================
template<typename T, size_t Size>
class LockFreeRingBuffer {
private:
    static_assert((Size & (Size - 1)) == 0, "Size must be power of 2");

    std::array<T, Size> buffer_;
    std::atomic<size_t> write_pos_{0};
    std::atomic<size_t> read_pos_{0};

public:
    bool push(const T& item) {
        const size_t current_write = write_pos_.load(std::memory_order_relaxed);
        const size_t next_write = (current_write + 1) & (Size - 1);

        if (next_write == read_pos_.load(std::memory_order_acquire)) {
            return false; // é˜Ÿåˆ—æ»¡
        }

        buffer_[current_write] = item;
        write_pos_.store(next_write, std::memory_order_release);
        return true;
    }

    bool pop(T& item) {
        const size_t current_read = read_pos_.load(std::memory_order_relaxed);

        if (current_read == write_pos_.load(std::memory_order_acquire)) {
            return false; // é˜Ÿåˆ—ç©º
        }

        item = buffer_[current_read];
        read_pos_.store((current_read + 1) & (Size - 1), std::memory_order_release);
        return true;
    }

    size_t size() const {
        const size_t write = write_pos_.load(std::memory_order_acquire);
        const size_t read = read_pos_.load(std::memory_order_acquire);
        return (write - read) & (Size - 1);
    }

    bool empty() const {
        return read_pos_.load(std::memory_order_acquire) ==
               write_pos_.load(std::memory_order_acquire);
    }

    bool full() const {
        const size_t write = write_pos_.load(std::memory_order_relaxed);
        const size_t next_write = (write + 1) & (Size - 1);
        return next_write == read_pos_.load(std::memory_order_acquire);
    }
};

// ==================== ä¼˜åŒ–çš„æ•°æ®åŒ…é˜Ÿåˆ— ====================
class OptimizedPacketQueue {
private:
    static const size_t RING_BUFFER_SIZE = 16384; // å¿…é¡»æ˜¯2çš„å¹‚
    std::vector<LockFreeRingBuffer<std::shared_ptr<PacketData>, RING_BUFFER_SIZE>> buffers_;
    std::atomic<size_t> next_buffer_{0};
    std::atomic<uint64_t> total_packets_{0};

public:
    OptimizedPacketQueue(size_t num_buffers = 4) : buffers_(num_buffers) {}

    bool push(const std::vector<uint8_t>& data) {
        auto packet_data = std::make_shared<PacketData>(data);
        size_t buffer_idx = next_buffer_.fetch_add(1) % buffers_.size();

        if (buffers_[buffer_idx].push(packet_data)) {
            total_packets_.fetch_add(1);
            return true;
        }
        return false;
    }

    bool pop(std::shared_ptr<PacketData>& packet_data, size_t buffer_idx = 0) {
        if (buffer_idx >= buffers_.size()) {
            buffer_idx = 0;
        }
        return buffers_[buffer_idx].pop(packet_data);
    }

    size_t get_buffer_count() const {
        return buffers_.size();
    }

    uint64_t get_total_packets() const {
        return total_packets_.load();
    }

    size_t total_size() const {
        size_t total = 0;
        for (const auto& buffer : buffers_) {
            total += buffer.size();
        }
        return total;
    }
};

// ==================== å¢å¼ºçš„æ•°æ®åŒ…é˜Ÿåˆ— ====================
class EnhancedPacketQueue {
private:
    OptimizedPacketQueue optimized_queue_;
    std::atomic<bool> stopped_{false};
    std::queue<TimestampedPacket> queue_;
    mutable std::mutex mutex_;
    std::condition_variable cond_;
    std::atomic<uint64_t> total_packets_{0};
    std::atomic<uint64_t> processed_packets_{0};

public:
    EnhancedPacketQueue() : optimized_queue_(4) {} // 4ä¸ªç¯å½¢ç¼“å†²åŒº

    // ä¿æŒåŸæœ‰æ¥å£å…¼å®¹æ€§
    bool push(const std::vector<uint8_t>& data, const ip::udp::endpoint& ep) {
        total_packets_.fetch_add(1);
        return optimized_queue_.push(data);
    }

    bool pop(TimestampedPacket& packet) {
        std::shared_ptr<PacketData> packet_data;

        // å°è¯•ä»ä¸åŒçš„ç¼“å†²åŒºè·å–æ•°æ®
        for (size_t i = 0; i < optimized_queue_.get_buffer_count(); ++i) {
            if (optimized_queue_.pop(packet_data, i)) {
                packet.data = packet_data->data;
                packet.receive_time = packet_data->timestamp;
                packet.process_start_time = std::chrono::steady_clock::now();
                processed_packets_.fetch_add(1);
                return true;
            }
        }

        if (stopped_) return false;

        // çŸ­æš‚ç­‰å¾…
        std::this_thread::sleep_for(std::chrono::microseconds(50));
        return false;
    }

    void stop() {
        stopped_ = true;
    }

    uint64_t getTotalPackets() const {
        return optimized_queue_.get_total_packets();
    }

    uint64_t getProcessedPackets() const {
        return processed_packets_.load();
    }

    size_t getQueueSize() const {
        return optimized_queue_.total_size();
    }
};

// ==================== æ•°æ®åŒ…å¤´éƒ¨ä¿¡æ¯ç»“æ„ ====================
struct HeaderInfo {
    bool power_spectra;
    bool multi_beam;
    int beam_id;
    int polarization;
    uint64_t sequence;
};

class MyPacket {
public:
    // æ„é€ å‡½æ•°ï¼šæ¥æ”¶åŸå§‹æ•°æ®åŒ…å’Œç½‘ç»œç«¯ç‚¹ä¿¡æ¯
    MyPacket(const std::vector<uint8_t>& buffer, const ip::udp::endpoint& endpoint)
        : buffer_(buffer), endpoint_(endpoint) {
        parseHeader();  // è‡ªåŠ¨è§£æå¤´éƒ¨ä¿¡æ¯
    }

     // è·å–è§£æåçš„å¤´éƒ¨ä¿¡æ¯
    HeaderInfo getHeader() const {
        return header_;
    }

    // è·å–æœ‰æ•ˆè½½è·æ•°æ®æŒ‡é’ˆ(4096å­—èŠ‚)
    const uint8_t* getPayload() const {
        if (buffer_.size() < PACKET_HEADER_SIZE + PACKET_PAYLOAD_SIZE) {
            throw std::runtime_error("Buffer too small to contain payload");
        }
        return buffer_.data() + PACKET_HEADER_SIZE;
    }

    // è·å–æœ‰æ•ˆè½½è·å¤§å°
    size_t getPayloadSize() const {
        return PACKET_PAYLOAD_SIZE;
    }

private:
    std::vector<uint8_t> buffer_;    // åŸå§‹æ•°æ®åŒ…ç¼“å†²åŒº
    ip::udp::endpoint endpoint_;     // ç½‘ç»œç«¯ç‚¹ä¿¡æ¯
    HeaderInfo header_;              // è§£æåçš„å¤´éƒ¨ä¿¡æ¯

    void parseHeader() {
        if (buffer_.size() < PACKET_HEADER_SIZE) {
            throw std::runtime_error("Buffer too small to contain header");
        }
        // å°†å‰8å­—èŠ‚è§£é‡Šä¸º64ä½æ•´æ•°
        uint64_t bitmask = *reinterpret_cast<const uint64_t*>(buffer_.data());
        // ä½å­—æ®µè§£æï¼š
        uint64_t seq_number = bitmask & ((1ULL << 56) - 1);
        bool bit7 = (bitmask >> 63) & 1;
        bool bit6 = (bitmask >> 62) & 1;
        int beam_id = (bitmask >> 57) & 0b11111;
        // æåŒ–ä¿¡æ¯ä»IPåœ°å€æœ€åä¸€ä½æ¨å¯¼
        int polarization = (endpoint_.address().to_string().back() - '0') % 2;
          // æ„é€ å¤´éƒ¨ä¿¡æ¯ç»“æ„
        header_ = {
            bit7 == 0,  // power_spectra
            bit6 == 1,  // multi_beam
            beam_id,
            polarization,
            seq_number
        };
    }
};

class OptimizedUDPServer {
public:
    OptimizedUDPServer(unsigned short port) : port_(port), running_(true) {
        for (int i = 0; i < NUM_RECV_THREADS; ++i) {
            int sockfd = create_socket(port);
            sockets_.push_back(sockfd);
        }

        std::cout << "ğŸš€ ä¼˜åŒ–UDPæœåŠ¡å™¨å¯åŠ¨ï¼Œç«¯å£: " << port
                  << "ï¼Œæ¥æ”¶çº¿ç¨‹æ•°: " << NUM_RECV_THREADS << std::endl;

        for (int i = 0; i < NUM_RECV_THREADS; ++i) {
            recv_threads_.emplace_back([this, i]() {
                receive_thread_func(sockets_[i]);
            });
        }
    }

    ~OptimizedUDPServer() {
        stop();
    }

    void stop() {
        running_ = false;
        for (int sockfd : sockets_) {
            if (sockfd >= 0) {
                close(sockfd);
            }
        }
        for (auto& t : recv_threads_) {
            if (t.joinable()) {
                t.join();
            }
        }
    }

    EnhancedPacketQueue& get_queue() { return packet_queue_; }

    // æ–°å¢ï¼šç½‘ç»œæ€§èƒ½æµ‹è¯•
    void performNetworkTest() {
        std::cout << "ğŸ” å¼€å§‹ç½‘ç»œæ€§èƒ½æµ‹è¯•..." << std::endl;

        auto start_time = std::chrono::steady_clock::now();
        uint64_t start_packets = packet_queue_.getTotalPackets();

        std::this_thread::sleep_for(std::chrono::seconds(10));

        auto end_time = std::chrono::steady_clock::now();
        uint64_t end_packets = packet_queue_.getTotalPackets();

        auto duration = std::chrono::duration_cast<std::chrono::seconds>(end_time - start_time);
        uint64_t packets_received = end_packets - start_packets;

        double packets_per_second = static_cast<double>(packets_received) / duration.count();
        double mbps = (packets_per_second * BUFFER_SIZE * 8) / (1024 * 1024);

        std::cout << "ğŸ“Š ç½‘ç»œæ€§èƒ½æµ‹è¯•ç»“æœ:" << std::endl;
        std::cout << "   æ¥æ”¶é€Ÿç‡: " << packets_per_second << " packets/s" << std::endl;
        std::cout << "   å¸¦å®½åˆ©ç”¨ç‡: " << mbps << " Mbps" << std::endl;
        std::cout << "   ç†è®ºæœ€å¤§åå: " << (packets_per_second * 1.2) << " packets/s" << std::endl;

        g_metrics.updateReceiveRate(packets_per_second);
    }

    uint64_t getDroppedPackets() const {
        return dropped_packets_.load();
    }

private:
    int create_socket(unsigned short port) {
        int sockfd = socket(AF_INET, SOCK_DGRAM, 0);
        if (sockfd < 0) {
            throw std::runtime_error("Failed to create socket");
        }

        int opt = 1;
        if (setsockopt(sockfd, SOL_SOCKET, SO_REUSEADDR, &opt, sizeof(opt)) < 0) {
            close(sockfd);
            throw std::runtime_error("Failed to set SO_REUSEADDR");
        }

        if (setsockopt(sockfd, SOL_SOCKET, SO_REUSEPORT, &opt, sizeof(opt)) < 0) {
            std::cerr << "Warning: SO_REUSEPORT not supported" << std::endl;
        }

        int buffer_size = 64 * 1024 * 1024;
        if (setsockopt(sockfd, SOL_SOCKET, SO_RCVBUF, &buffer_size, sizeof(buffer_size)) < 0) {
            std::cerr << "Warning: Failed to set receive buffer size" << std::endl;
        }

        int flags = fcntl(sockfd, F_GETFL, 0);
        if (flags < 0 || fcntl(sockfd, F_SETFL, flags | O_NONBLOCK) < 0) {
            close(sockfd);
            throw std::runtime_error("Failed to set non-blocking mode");
        }

        struct sockaddr_in addr;
        memset(&addr, 0, sizeof(addr));
        addr.sin_family = AF_INET;
        addr.sin_addr.s_addr = INADDR_ANY;
        addr.sin_port = htons(port);

        if (bind(sockfd, (struct sockaddr*)&addr, sizeof(addr)) < 0) {
            close(sockfd);
            throw std::runtime_error("Failed to bind socket to port " + std::to_string(port));
        }

        return sockfd;
    }

    void receive_thread_func(int sockfd) {
        std::vector<struct mmsghdr> msgs(BATCH_SIZE);
        std::vector<struct sockaddr_in> addrs(BATCH_SIZE);
        std::vector<std::vector<uint8_t>> buffers(BATCH_SIZE);
        std::vector<struct iovec> iovs(BATCH_SIZE);

        for (int i = 0; i < BATCH_SIZE; ++i) {
            buffers[i].resize(BUFFER_SIZE);
            iovs[i].iov_base = buffers[i].data();
            iovs[i].iov_len = BUFFER_SIZE;
            msgs[i].msg_hdr.msg_iov = &iovs[i];
            msgs[i].msg_hdr.msg_iovlen = 1;
            msgs[i].msg_hdr.msg_name = &addrs[i];
            msgs[i].msg_hdr.msg_namelen = sizeof(struct sockaddr_in);
            msgs[i].msg_len = 0;
        }

        while (running_) {
            int count = recvmmsg(sockfd, msgs.data(), BATCH_SIZE, MSG_DONTWAIT, nullptr);

            if (count > 0) {
                for (int i = 0; i < count; ++i) {
                    if (msgs[i].msg_len == BUFFER_SIZE) {
                        std::vector<uint8_t> data(buffers[i].begin(),
                                                buffers[i].begin() + msgs[i].msg_len);

                        ip::udp::endpoint ep(
                            ip::address_v4(ntohl(addrs[i].sin_addr.s_addr)),
                            ntohs(addrs[i].sin_port)
                        );

                        if (!packet_queue_.push(data, ep)) {
                            dropped_packets_++;
                        }
                    }
                }

            } else if (count < 0) {
                if (errno == EAGAIN || errno == EWOULDBLOCK) {
                    g_metrics.network_timeouts++;
                    std::this_thread::sleep_for(std::chrono::microseconds(100));
                } else {
                    g_metrics.network_errors++;
                    std::cerr << "recvmmsg error: " << strerror(errno) << std::endl;
                    std::this_thread::sleep_for(std::chrono::milliseconds(10));
                }
            } else {
                std::this_thread::sleep_for(std::chrono::microseconds(100));
            }
        }
    }

    unsigned short port_;
    std::atomic<bool> running_;
    std::vector<int> sockets_;
    std::vector<std::thread> recv_threads_;
    EnhancedPacketQueue packet_queue_;
    std::atomic<uint64_t> dropped_packets_{0};
};

class ThreadSafeQueue {
public:
        // é»˜è®¤æ„é€ å‡½æ•°
        ThreadSafeQueue() = default;
        // ç¦æ­¢æ‹·è´æ„é€ å’Œèµ‹å€¼
        ThreadSafeQueue(const ThreadSafeQueue&) = delete;
        ThreadSafeQueue& operator=(const ThreadSafeQueue&) = delete;

        // å°†å…ƒç´ æ¨å…¥é˜Ÿåˆ—
        void push(const std::vector<float>& item) {
            std::lock_guard<std::mutex> lock(m_mutex);
            m_queue.push(item);
            m_cond.notify_one();
        }

        // å°è¯•ä»é˜Ÿåˆ—ä¸­å¼¹å‡ºå…ƒç´ 
        bool try_pop(std::vector<float>& item) {
            std::lock_guard<std::mutex> lock(m_mutex);
            if (m_queue.empty()) {
                return false;
            }
            item = m_queue.front();
            m_queue.pop();
            return true;
        }

        // ç­‰å¾…å¹¶ä»é˜Ÿåˆ—ä¸­å¼¹å‡ºå…ƒç´ 
        void wait_and_pop(std::vector<float>& item) {
            std::unique_lock<std::mutex> lock(m_mutex);
            m_cond.wait(lock, [this] { return !m_queue.empty(); });
            item = m_queue.front();
            m_queue.pop();
        }

        // æ£€æŸ¥é˜Ÿåˆ—æ˜¯å¦ä¸ºç©º
        bool empty() const {
            std::lock_guard<std::mutex> lock(m_mutex);
            return m_queue.empty();
        }

        // è·å–é˜Ÿåˆ—å¤§å°
        size_t size() const {
            std::lock_guard<std::mutex> lock(m_mutex);
            return m_queue.size();
        }

private:
        mutable std::mutex m_mutex;               // ä¿æŠ¤é˜Ÿåˆ—çš„äº’æ–¥é”
        std::queue<std::vector<float>> m_queue;   // å®é™…çš„é˜Ÿåˆ—å®¹å™¨
        std::condition_variable m_cond;           // æ¡ä»¶å˜é‡ï¼Œç”¨äºçº¿ç¨‹é—´åŒæ­¥
};

// ==================== å¢å¼ºçš„FITSä¿å­˜å‡½æ•° ====================
void saveToFitsFileBatch(const std::vector<std::vector<float>>& data_batch, const std::string& filename) {
    auto start_time = std::chrono::steady_clock::now();

    if (data_batch.empty()) return;

    fitsfile* fptr;
    int status = 0;

    // åˆ›å»ºFITSæ–‡ä»¶
    fits_create_file(&fptr, filename.c_str(), &status);
    if (status != 0) {
        g_metrics.file_write_errors++;
        char error_text[30];
        fits_get_errstatus(status, error_text);
        std::cerr << "FITSåˆ›å»ºé”™è¯¯: " << error_text << " (æ–‡ä»¶: " << filename << ")" << std::endl;
        return;
    }

    // åˆ›å»ºä¸»HDU
    fits_create_img(fptr, FLOAT_IMG, 0, nullptr, &status);

    // æ·»åŠ å¤´éƒ¨ä¿¡æ¯
    bool simple = true;
    short bitpix = 32;
    int naxis = 0;
    bool extend = true;
    const char* hdrver = "3.4";
    const char* fitstype = "PSRFITS";

    fits_update_key(fptr, TLOGICAL, "SIMPLE", &simple, nullptr, &status);
    fits_update_key(fptr, TSHORT, "BITPIX", &bitpix, nullptr, &status);
    fits_update_key(fptr, TINT, "NAXIS", &naxis, nullptr, &status);
    fits_update_key(fptr, TLOGICAL, "EXTEND", &extend, nullptr, &status);
    fits_update_key(fptr, TSTRING, "HDRVER", const_cast<char*>(hdrver), nullptr, &status);
    fits_update_key(fptr, TSTRING, "FITSTYPE", const_cast<char*>(fitstype), nullptr, &status);

    // åˆ›å»º2Dæ‰©å±•HDU
    long naxes[2] = {
        static_cast<long>(data_batch[0].size()),
        static_cast<long>(data_batch.size())
    };
    fits_create_img(fptr, FLOAT_IMG, 2, naxes, &status);

    int num_spectra = static_cast<int>(data_batch.size());
    int spec_length = static_cast<int>(data_batch[0].size());
    fits_update_key(fptr, TINT, "NSPEC", &num_spectra, "Number of spectra in this file", &status);
    fits_update_key(fptr, TINT, "SPECLEN", &spec_length, "Length of each spectrum", &status);

    // å±•å¹³æ•°æ®
    std::vector<float> flattened_data;
    flattened_data.reserve(data_batch.size() * data_batch[0].size());

    for (const auto& spectrum : data_batch) {
        flattened_data.insert(flattened_data.end(), spectrum.begin(), spectrum.end());
    }

    // å†™å…¥æ•°æ®
    fits_write_img(fptr, TFLOAT, 1, flattened_data.size(),
                   const_cast<void*>(static_cast<const void*>(flattened_data.data())), &status);

    if (status != 0) {
        g_metrics.file_write_errors++;
        char error_text[30];
        fits_get_errstatus(status, error_text);
        std::cerr << "FITSå†™å…¥é”™è¯¯: " << error_text << " (æ–‡ä»¶: " << filename << ")" << std::endl;
    }

    fits_close_file(fptr, &status);

    auto end_time = std::chrono::steady_clock::now();
    auto duration = std::chrono::duration_cast<std::chrono::microseconds>(end_time - start_time);
    g_save_latency.addSample(duration.count());
    g_metrics.avg_save_latency_us.store(g_save_latency.getAverageLatency());
}

// ==================== å¢å¼ºçš„DataAccumulator ====================
class DataAccumulator {
public:
    ThreadSafeQueue fftQueue;
    static const int BATCH_SAVE_SIZE = 10;
    std::vector<std::vector<float>> save_batch_;
    std::mutex save_batch_mutex_;

    DataAccumulator() = default;
    DataAccumulator(bool multi_beam, int polarization)
        : multi_beam_(multi_beam), polarization_(polarization), packet_count_(0), file_counter_(0), get_chunk_idx(0) {
        try {
            acc_buffer_ = new int8_t[ACC_BUFFER_SIZE];
            save_batch_.reserve(BATCH_SAVE_SIZE);
        } catch (const std::bad_alloc& e) {
            g_metrics.memory_allocation_failures++;
            std::cerr << "å†…å­˜åˆ†é…å¤±è´¥: " << e.what() << std::endl;
            throw;
        }
    }

    ~DataAccumulator() {
        delete[] acc_buffer_;
    }

    void addPacket(const MyPacket& packet) {
        std::unique_lock<std::mutex> lock(mutex_);

        bool has_space = cond_.wait_for(lock, std::chrono::milliseconds(10),
            [this]{ return (packet_count_*PACKET_PAYLOAD_SIZE-get_chunk_idx * CHUNK_SIZE < ACC_BUFFER_SIZE)||stopped_; });

        if (!has_space) {
            dropped_packets_++;
            if (dropped_packets_ % 1000 == 0) {
                std::cout << "âš ï¸  è­¦å‘Š: DataAccumulator(" << multi_beam_ << "," << polarization_
                          << ") ç¼“å†²åŒºæ»¡ï¼Œå·²ä¸¢å¼ƒ " << dropped_packets_ << " ä¸ªæ•°æ®åŒ…" << std::endl;
            }
            return;
        }

        if(stopped_) {
            return;
        }

        const int8_t* payload = reinterpret_cast<const int8_t*>(packet.getPayload());
        size_t write_pos = (packet_count_ * PACKET_PAYLOAD_SIZE) % ACC_BUFFER_SIZE;
        memcpy(acc_buffer_ + write_pos, payload, PACKET_PAYLOAD_SIZE);
        packet_count_++;
        cond_.notify_one();
    }

    void printState() {
        size_t remain_packet_count = packet_count_ - get_chunk_idx*PACKETS_PER_CHUNK;
        size_t process_rate = get_chunk_idx - last_chunk_idx;
        last_chunk_idx = get_chunk_idx;
        if(process_rate > max_rate){
            max_rate = process_rate;
        }
        double rate = max_rate*0.1875;
        double last_rate = process_rate*0.1875;
        size_t fft_queue_size = fftQueue.size();

        std::cout << "ğŸ“Š Accumulator(" << multi_beam_ << "," << polarization_ << "): "
                  << "remain_pkts=" << remain_packet_count
                  << ", chunks=" << get_chunk_idx
                  << ", total_pkts=" << packet_count_
                  << ", fft_queue=" << fft_queue_size
                  << ", max_rate=" << rate << "MB/s"
                  << ", last_rate=" << last_rate << "MB/s"
                  << ", files=" << file_counter_
                  << ", dropped=" << dropped_packets_ << std::endl;
    }

    bool popFromChunkQueue(std::vector<int8_t>& data){
        std::unique_lock<std::mutex> chunk_lock(chunk_queue_mutex_);
        if(stopped_) return false;
        if((packet_count_ < (get_chunk_idx + 1) * PACKETS_PER_CHUNK)) return false;

        data.clear();
        size_t read_pos = (get_chunk_idx%MAX_CHUNK_COUNT)*CHUNK_SIZE;
        data.insert(data.end(), acc_buffer_+read_pos, acc_buffer_+read_pos+CHUNK_SIZE);
        get_chunk_idx++;
        return true;
    }

    void stop() {
        std::lock_guard<std::mutex> lock(mutex_);
        stopped_ = true;
        cond_.notify_all();
    }

    std::string generateFitsFileName() {
        std::lock_guard<std::mutex> lock(file_counter_mutex_);
        return (multi_beam_ ? "multi" : "single") + std::string("_") +
               std::to_string(polarization_) + std::string("_") +
               std::to_string(file_counter_++) + std::string(".fits");
    }

    bool addToBatch(const std::vector<float>& fft_result) {
        std::lock_guard<std::mutex> lock(save_batch_mutex_);
        save_batch_.push_back(fft_result);
        return save_batch_.size() >= BATCH_SAVE_SIZE;
    }

    std::vector<std::vector<float>> getBatchAndClear() {
        std::lock_guard<std::mutex> lock(save_batch_mutex_);
        std::vector<std::vector<float>> result = std::move(save_batch_);
        save_batch_.clear();
        save_batch_.reserve(BATCH_SAVE_SIZE);
        return result;
    }

    std::vector<std::vector<float>> getRemainderBatch() {
        std::lock_guard<std::mutex> lock(save_batch_mutex_);
        if (save_batch_.empty()) {
            return {};
        }
        std::vector<std::vector<float>> result = std::move(save_batch_);
        save_batch_.clear();
        return result;
    }

    size_t getRemainPackets() const {
        return packet_count_ - get_chunk_idx * PACKETS_PER_CHUNK;
    }

    size_t getFileCount() const {
        std::lock_guard<std::mutex> lock(file_counter_mutex_);
        return file_counter_;
    }

    size_t getChunkCount() const {
        return get_chunk_idx;
    }

    size_t getTotalPackets() const {
        return packet_count_;
    }

    size_t getDroppedPackets() const {
        return dropped_packets_;
    }

private:
    bool multi_beam_;
    int polarization_;
    int8_t *acc_buffer_;
    int packet_count_;
    int file_counter_;
    size_t get_chunk_idx = 0;
    mutable size_t last_chunk_idx = 0;
    size_t max_rate = 0;
    std::mutex mutex_;
    mutable std::mutex file_counter_mutex_;
    std::mutex chunk_queue_mutex_;
    std::condition_variable cond_;
    bool stopped_ = false;
    std::atomic<size_t> dropped_packets_{0};
};

// GPUç›‘æ§ç±»
struct GPUUtilization {
    int gpu_util_percent = 0;
    int memory_util_percent = 0;
    int temperature = 0;
    int power_usage = 0;
    int memory_used_mb = 0;
    int memory_total_mb = 0;
    std::string gpu_name;
    bool valid = false;
};

class GPUMonitor {
public:
    GPUMonitor() = default;

    GPUUtilization getGPUUtilizationViaCUDA(int device_id = 0) {
        GPUUtilization util;
        int device_count = 0;
        cudaError_t error = cudaGetDeviceCount(&device_count);
        if (error != cudaSuccess || device_count == 0 || device_id >= device_count) {
            return util;
        }

        cudaSetDevice(device_id);
        cudaDeviceProp prop;
        cudaGetDeviceProperties(&prop, device_id);
        util.gpu_name = prop.name;

        size_t free_mem, total_mem;
        if (cudaMemGetInfo(&free_mem, &total_mem) == cudaSuccess) {
            util.memory_total_mb = total_mem / (1024 * 1024);
            util.memory_used_mb = (total_mem - free_mem) / (1024 * 1024);
            util.memory_util_percent = (int)((total_mem - free_mem) * 100 / total_mem);
        }

        util.valid = true;
        return util;
    }
};

// ä¿®æ”¹GPUç›‘æ§ç±»ä»¥æ”¯æŒå¤šGPU
class MultiGPUMonitor {
public:
    MultiGPUMonitor() = default;

    void printMultiGPUStatus() {
        int gpu_count = get_available_gpu_count();

        std::cout << "ğŸ® å¤šGPUç³»ç»ŸçŠ¶æ€ (å…±" << gpu_count << "ä¸ªGPU):" << std::endl;

        // æ‰“å°æ¯ä¸ªGPUçš„çŠ¶æ€
        for (int i = 0; i < gpu_count; ++i) {
            printSingleGPUStatus(i);
        }

        // æ‰“å°å¤šGPUç»Ÿè®¡
        print_multi_gpu_stats();

        // è®¡ç®—æ•´ä½“åˆ©ç”¨ç‡
        float total_util = 0.0f;
        for (int i = 0; i < gpu_count; ++i) {
            total_util += getGPUUtilization(i);
        }
        float avg_util = gpu_count > 0 ? total_util / gpu_count : 0.0f;
        g_metrics.gpu_utilization_avg.store(avg_util);

        std::cout << "ğŸ“Š å¤šGPUå¹³å‡åˆ©ç”¨ç‡: " << std::fixed << std::setprecision(1)
                  << avg_util << "%" << std::endl;
    }

private:
    void printSingleGPUStatus(int gpu_id) {
        cudaSetDevice(gpu_id);

        cudaDeviceProp prop;
        cudaGetDeviceProperties(&prop, gpu_id);

        size_t free_mem, total_mem;
        if (cudaMemGetInfo(&free_mem, &total_mem) == cudaSuccess) {
            int memory_util_percent = (int)((total_mem - free_mem) * 100 / total_mem);
            int memory_used_mb = (total_mem - free_mem) / (1024 * 1024);
            int memory_total_mb = total_mem / (1024 * 1024);

            std::string mem_color = memory_util_percent >= 80 ? "ğŸ”´" :
                                   memory_util_percent >= 50 ? "ğŸŸ¡" : "ğŸŸ¢";

            std::cout << "   " << mem_color << " GPU " << gpu_id << " (" << prop.name << "): "
                      << "æ˜¾å­˜=" << memory_util_percent << "% "
                      << "(" << memory_used_mb << "MB/" << memory_total_mb << "MB)" << std::endl;
        }
    }

    float getGPUUtilization(int gpu_id) {
        // ç®€åŒ–çš„GPUåˆ©ç”¨ç‡ä¼°ç®—
        // å®é™…é¡¹ç›®ä¸­å¯ä»¥ä½¿ç”¨NVMLåº“è·å–æ›´ç²¾ç¡®çš„åˆ©ç”¨ç‡
        return g_cuda_estimator.getEstimatedUtilization();
    }
};

static MultiGPUMonitor g_multi_gpu_monitor;

// ==================== å¢å¼ºçš„GPUçŠ¶æ€æ‰“å° ====================
void print_gpu_resource_status() {
    static GPUMonitor monitor;
    GPUUtilization util = monitor.getGPUUtilizationViaCUDA(0);

    if (util.valid) {
        float estimated_util = g_cuda_estimator.getEstimatedUtilization();
        size_t active_kernels = g_cuda_estimator.getActiveKernels();

        std::string util_color = estimated_util >= 70 ? "ğŸ”´" :
                               estimated_util >= 30 ? "ğŸŸ¡" : "ğŸŸ¢";
        std::string mem_color = util.memory_util_percent >= 80 ? "ğŸ”´" :
                               util.memory_util_percent >= 50 ? "ğŸŸ¡" : "ğŸŸ¢";

        std::cout << util_color << " GPUçŠ¶æ€: " << util.gpu_name << std::endl;
        std::cout << "   ğŸ“Š ä¼°ç®—GPUåˆ©ç”¨ç‡: " << std::fixed << std::setprecision(1)
                  << estimated_util << "% (æ´»è·ƒå†…æ ¸: " << active_kernels << ")" << std::endl;
        std::cout << "   " << mem_color << " æ˜¾å­˜ä½¿ç”¨: " << util.memory_util_percent << "% "
                  << "(" << util.memory_used_mb << "MB/" << util.memory_total_mb << "MB)" << std::endl;

        // æ·»åŠ å»¶è¿Ÿç»Ÿè®¡
        std::cout << "   â±ï¸  FFTå¹³å‡å»¶è¿Ÿ: " << g_fft_latency.getAverageLatency() << "Î¼s" << std::endl;
        std::cout << "   ğŸ’¾ ä¿å­˜å¹³å‡å»¶è¿Ÿ: " << g_save_latency.getAverageLatency() << "Î¼s" << std::endl;
    } else {
        std::cout << "ğŸ”´ GPUçŠ¶æ€: æ— æ³•è·å–GPUä¿¡æ¯" << std::endl;
    }
}

// ä¿®æ”¹å¢å¼ºçš„ç›‘æ§çº¿ç¨‹ä»¥æ”¯æŒå¤šGPU
void monitor_thread_enhanced_multigpu(OptimizedUDPServer& server, DataAccumulator accumulators[4], std::atomic<bool>& running) {
    auto last_time = steady_clock::now();
    uint64_t last_total = 0;
    uint64_t last_processed = 0;
    size_t monitor_count = 0;
    auto baseline_start_time = steady_clock::now();
    uint64_t baseline_processed = 0;
    bool baseline_recorded = false;

    while (running) {
        std::this_thread::sleep_for(seconds(1));
        monitor_count++;

        auto now = steady_clock::now();
        auto elapsed = duration_cast<duration<double>>(now - last_time).count();
        last_time = now;

        uint64_t current_total = server.get_queue().getTotalPackets();
        uint64_t current_processed = server.get_queue().getProcessedPackets();
        uint64_t current_dropped = server.getDroppedPackets();
        size_t queue_size = server.get_queue().getQueueSize();

        uint64_t total_diff = current_total - last_total;
        uint64_t processed_diff = current_processed - last_processed;

        last_total = current_total;
        last_processed = current_processed;

        double receive_rate = total_diff / elapsed;
        double process_rate = processed_diff / elapsed;

        // è®¡ç®—å¤šGPUåŠ é€Ÿæ¯”ï¼ˆç›¸å¯¹äºå•GPUç†è®ºæ€§èƒ½ï¼‰
        if (!baseline_recorded && monitor_count > 10) {
            baseline_start_time = now;
            baseline_processed = current_processed;
            baseline_recorded = true;
        }

        if (baseline_recorded && monitor_count > 20) {
            auto baseline_elapsed = duration_cast<duration<double>>(now - baseline_start_time).count();
            double actual_rate = (current_processed - baseline_processed) / baseline_elapsed;
            double theoretical_single_gpu_rate = actual_rate / get_available_gpu_count();
            double speedup = actual_rate / theoretical_single_gpu_rate;
            g_metrics.multi_gpu_speedup.store(speedup);
        }

        // æ›´æ–°å…¨å±€æ€§èƒ½æŒ‡æ ‡
        g_metrics.updateReceiveRate(receive_rate);
        g_metrics.updateProcessRate(process_rate);
        g_metrics.active_gpu_count.store(get_available_gpu_count());

        size_t total_remain_packets = 0;
        size_t total_fft_queue_size = 0;
        size_t total_files = 0;
        size_t total_acc_dropped = 0;

        for (size_t i = 0; i < 4; ++i) {
            total_remain_packets += accumulators[i].getRemainPackets();
            total_fft_queue_size += accumulators[i].fftQueue.size();
            total_files += accumulators[i].getFileCount();
            total_acc_dropped += accumulators[i].getDroppedPackets();
        }

        // ç“¶é¢ˆæ£€æµ‹ï¼ˆå¤šGPUç‰ˆæœ¬ï¼‰
        std::string bottleneck_warning = "";
        if (queue_size > MAX_QUEUE_SIZE * 0.8) {
            bottleneck_warning += "âš ï¸ ç½‘ç»œé˜Ÿåˆ—æ¥è¿‘æ»¡è½½! ";
        }
        if (total_fft_queue_size > 100 * get_available_gpu_count()) {
            bottleneck_warning += "âš ï¸ FFTé˜Ÿåˆ—ç§¯å‹(å¤šGPU)! ";
        }
        if (total_remain_packets > 10000) {
            bottleneck_warning += "âš ï¸ æ•°æ®åŒ…ç§¯å‹ä¸¥é‡! ";
        }
        if (g_metrics.cuda_resource_waits.load() > 0 && monitor_count % 5 == 0) {
            bottleneck_warning += "âš ï¸ GPUèµ„æºç«äº‰! ";
        }

        std::cout << "ğŸ“Š å¤šGPUç›‘æ§ç»Ÿè®¡: "
                  << "GPUæ•°=" << get_available_gpu_count() << ", "
                  << "æ¥æ”¶=" << std::fixed << std::setprecision(0) << receive_rate << "pkt/s, "
                  << "å¤„ç†=" << process_rate << "pkt/s, "
                  << "åŠ é€Ÿæ¯”=" << std::setprecision(2) << g_metrics.multi_gpu_speedup.load() << "x, "
                  << "é˜Ÿåˆ—=" << queue_size << ", "
                  << "ç§¯å‹=" << total_remain_packets << "pkts, "
                  << "FFTé˜Ÿåˆ—=" << total_fft_queue_size << ", "
                  << "æ–‡ä»¶=" << total_files << ", "
                  << "ä¸¢åŒ…=" << total_acc_dropped << " " << bottleneck_warning << std::endl;

        // æ˜¾ç¤ºå¤šGPUçŠ¶æ€
        g_multi_gpu_monitor.printMultiGPUStatus();

        // æ˜¾ç¤ºæ¯ä¸ªaccumulatorçš„çŠ¶æ€
        for (size_t i = 0; i < 4; ++i) {
            accumulators[i].printState();
        }

        // æ¯30ç§’æ‰“å°è¯¦ç»†æ€§èƒ½æŠ¥å‘Š
        if (monitor_count % 30 == 0) {
            std::cout << "\nğŸ” ========== å¤šGPUè¯¦ç»†æ€§èƒ½æŠ¥å‘Š ========== ğŸ”" << std::endl;
            std::cout << "ğŸ® æ¿€æ´»GPUæ•°é‡: " << get_available_gpu_count() << std::endl;
            std::cout << "ğŸ“ˆ å³°å€¼æ¥æ”¶é€Ÿç‡: " << g_metrics.peak_receive_rate.load() << " pkt/s" << std::endl;
            std::cout << "ğŸ“ˆ å³°å€¼å¤„ç†é€Ÿç‡: " << g_metrics.peak_process_rate.load() << " pkt/s" << std::endl;
            std::cout << "ğŸš€ å¤šGPUåŠ é€Ÿæ¯”: " << g_metrics.multi_gpu_speedup.load() << "x" << std::endl;
            std::cout << "â±ï¸  å¹³å‡ç½‘ç»œå»¶è¿Ÿ: " << g_network_latency.getAverageLatency() << "Î¼s (æœ€å¤§: " << g_network_latency.getMaxLatency() << "Î¼s)" << std::endl;
            std::cout << "â±ï¸  å¹³å‡FFTå»¶è¿Ÿ: " << g_fft_latency.getAverageLatency() << "Î¼s (æœ€å¤§: " << g_fft_latency.getMaxLatency() << "Î¼s)" << std::endl;
            std::cout << "â±ï¸  å¹³å‡ä¿å­˜å»¶è¿Ÿ: " << g_save_latency.getAverageLatency() << "Î¼s (æœ€å¤§: " << g_save_latency.getMaxLatency() << "Î¼s)" << std::endl;
            std::cout << "âŒ ç½‘ç»œé”™è¯¯: " << g_metrics.network_errors.load() << std::endl;
            std::cout << "âŒ æ–‡ä»¶é”™è¯¯: " << g_metrics.file_write_errors.load() << std::endl;
            std::cout << "âŒ é˜Ÿåˆ—æº¢å‡º: " << g_metrics.queue_overflows.load() << std::endl;
            std::cout << "âŒ CUDAç­‰å¾…: " << g_metrics.cuda_resource_waits.load() << std::endl;
            std::cout << "==========================================\n" << std::endl;
        }
    }
}

// ==================== å¢å¼ºçš„ç›‘æ§çº¿ç¨‹ ====================
void monitor_thread_enhanced(OptimizedUDPServer& server, DataAccumulator accumulators[4], std::atomic<bool>& running) {
    auto last_time = steady_clock::now();
    uint64_t last_total = 0;
    uint64_t last_processed = 0;
    size_t monitor_count = 0;

    while (running) {
        std::this_thread::sleep_for(seconds(1));
        monitor_count++;

        auto now = steady_clock::now();
        auto elapsed = duration_cast<duration<double>>(now - last_time).count();
        last_time = now;

        uint64_t current_total = server.get_queue().getTotalPackets();
        uint64_t current_processed = server.get_queue().getProcessedPackets();
        uint64_t current_dropped = server.getDroppedPackets();
        size_t queue_size = server.get_queue().getQueueSize();

        uint64_t total_diff = current_total - last_total;
        uint64_t processed_diff = current_processed - last_processed;

        last_total = current_total;
        last_processed = current_processed;

        double receive_rate = total_diff / elapsed;
        double process_rate = processed_diff / elapsed;

        // æ›´æ–°å…¨å±€æ€§èƒ½æŒ‡æ ‡
        g_metrics.updateReceiveRate(receive_rate);
        g_metrics.updateProcessRate(process_rate);

        size_t total_remain_packets = 0;
        size_t total_fft_queue_size = 0;
        size_t total_files = 0;
        size_t total_acc_dropped = 0;

        for (size_t i = 0; i < 4; ++i) {
            total_remain_packets += accumulators[i].getRemainPackets();
            total_fft_queue_size += accumulators[i].fftQueue.size();
            total_files += accumulators[i].getFileCount();
            total_acc_dropped += accumulators[i].getDroppedPackets();
        }

        // ç“¶é¢ˆæ£€æµ‹
        std::string bottleneck_warning = "";
        if (queue_size > MAX_QUEUE_SIZE * 0.8) {
            bottleneck_warning += "âš ï¸ ç½‘ç»œé˜Ÿåˆ—æ¥è¿‘æ»¡è½½! ";
        }
        if (total_fft_queue_size > 100) {
            bottleneck_warning += "âš ï¸ FFTé˜Ÿåˆ—ç§¯å‹! ";
        }
        if (total_remain_packets > 10000) {
            bottleneck_warning += "âš ï¸ æ•°æ®åŒ…ç§¯å‹ä¸¥é‡! ";
        }

        std::cout << "ğŸ“Š ç›‘æ§ç»Ÿè®¡: "
                  << "æ¥æ”¶=" << std::fixed << std::setprecision(0) << receive_rate << "pkt/s, "
                  << "å¤„ç†=" << process_rate << "pkt/s, "
                  << "é˜Ÿåˆ—=" << queue_size << ", "
                  << "ç§¯å‹=" << total_remain_packets << "pkts, "
                  << "FFTé˜Ÿåˆ—=" << total_fft_queue_size << ", "
                  << "æ–‡ä»¶=" << total_files << ", "
                  << "ä¸¢åŒ…=" << total_acc_dropped << " " << bottleneck_warning << std::endl;

        print_gpu_resource_status();

        for (size_t i = 0; i < 4; ++i) {
            accumulators[i].printState();
        }

        // æ¯30ç§’æ‰“å°è¯¦ç»†æ€§èƒ½æŠ¥å‘Š
        if (monitor_count % 30 == 0) {
            std::cout << "\nğŸ” ========== è¯¦ç»†æ€§èƒ½æŠ¥å‘Š ========== ğŸ”" << std::endl;
            std::cout << "ğŸ“ˆ å³°å€¼æ¥æ”¶é€Ÿç‡: " << g_metrics.peak_receive_rate.load() << " pkt/s" << std::endl;
            std::cout << "ğŸ“ˆ å³°å€¼å¤„ç†é€Ÿç‡: " << g_metrics.peak_process_rate.load() << " pkt/s" << std::endl;
            std::cout << "â±ï¸  å¹³å‡ç½‘ç»œå»¶è¿Ÿ: " << g_network_latency.getAverageLatency() << "Î¼s (æœ€å¤§: " << g_network_latency.getMaxLatency() << "Î¼s)" << std::endl;
            std::cout << "â±ï¸  å¹³å‡FFTå»¶è¿Ÿ: " << g_fft_latency.getAverageLatency() << "Î¼s (æœ€å¤§: " << g_fft_latency.getMaxLatency() << "Î¼s)" << std::endl;
            std::cout << "â±ï¸  å¹³å‡ä¿å­˜å»¶è¿Ÿ: " << g_save_latency.getAverageLatency() << "Î¼s (æœ€å¤§: " << g_save_latency.getMaxLatency() << "Î¼s)" << std::endl;
            std::cout << "âŒ ç½‘ç»œé”™è¯¯: " << g_metrics.network_errors.load() << std::endl;
            std::cout << "âŒ æ–‡ä»¶é”™è¯¯: " << g_metrics.file_write_errors.load() << std::endl;
            std::cout << "âŒ é˜Ÿåˆ—æº¢å‡º: " << g_metrics.queue_overflows.load() << std::endl;
            std::cout << "âŒ CUDAç­‰å¾…: " << g_metrics.cuda_resource_waits.load() << std::endl;
            std::cout << "==========================================\n" << std::endl;
        }
    }
}

// ==================== å¢å¼ºçš„FFTçº¿ç¨‹ ====================
void fft_thread_optimized(DataAccumulator accumulators[4], std::atomic<bool>& running, size_t thread_id) {
    std::vector<int8_t> chunkData;
    std::vector<std::complex<float>> fft_result_complex;
    std::vector<float> fft_result_real;
    size_t acc_id = thread_id % 4;
    DataAccumulator* acc = &accumulators[acc_id];

    while (running) {
        if (acc->popFromChunkQueue(chunkData)) {
            try {
                g_cuda_estimator.kernelStart();
                auto fft_start_time = std::chrono::high_resolution_clock::now();

                bool success = false;
                int retry_count = 0;
                const int max_retries = 10;

                while (!success && retry_count < max_retries && running) {
                    success = cuda_fft_process_batch_async(chunkData, fft_result_complex);
                    if (!success) {
                        retry_count++;
                        g_metrics.cuda_resource_waits++;
                        std::this_thread::sleep_for(std::chrono::microseconds(50 * retry_count));
                    }
                }

                auto fft_end_time = std::chrono::high_resolution_clock::now();
                auto fft_duration = std::chrono::duration_cast<std::chrono::microseconds>(fft_end_time - fft_start_time);

                g_cuda_estimator.kernelEnd(fft_duration.count());
                g_fft_latency.addSample(fft_duration.count());
                g_metrics.avg_fft_latency_us.store(g_fft_latency.getAverageLatency());

                if (!success) {
                    std::cerr << "âš ï¸ FFTçº¿ç¨‹" << thread_id << ": CUDAèµ„æºæŒç»­ä¸å¯ç”¨ï¼Œè·³è¿‡å¤„ç†" << std::endl;
                    continue;
                }

                fft_result_real.clear();
                fft_result_real.reserve(fft_result_complex.size());

                for (const auto& complex_val : fft_result_complex) {
                    float magnitude_squared = complex_val.real() * complex_val.real() +
                                            complex_val.imag() * complex_val.imag();
                    fft_result_real.push_back(magnitude_squared);
                }

                acc->fftQueue.push(fft_result_real);

            } catch (const std::exception& e) {
                std::cerr << "âŒ CUDA FFTå¤„ç†é”™è¯¯: " << e.what() << std::endl;
            }
        } else {
            std::this_thread::sleep_for(std::chrono::microseconds(200));
        }
    }
}

// ==================== å¢å¼ºçš„ä¿å­˜çº¿ç¨‹ ====================
void save_thread_optimized_batch(DataAccumulator accumulators[4], std::atomic<bool>& running, size_t thread_id) {
    size_t acc_id = thread_id % 4;
    DataAccumulator* acc = &accumulators[acc_id];
    std::vector<float> fft_result;

    try {
        fs::create_directories("./output_fits");
    } catch (const std::exception& e) {
        std::cerr << "âŒ åˆ›å»ºè¾“å‡ºç›®å½•å¤±è´¥: " << e.what() << std::endl;
        g_metrics.file_write_errors++;
    }

    while (running) {
        if (acc->fftQueue.try_pop(fft_result)) {
            try {
                auto processing_start = std::chrono::steady_clock::now();
                bool batch_ready = acc->addToBatch(fft_result);

                if (batch_ready) {
                    auto start_time = std::chrono::steady_clock::now();

                    auto batch = acc->getBatchAndClear();
                    std::string filename = acc->generateFitsFileName();
                    saveToFitsFileBatch(batch, "./output_fits/" + filename);
                    saved_count++;

                    auto end_time = std::chrono::steady_clock::now();
                    auto duration = std::chrono::duration_cast<std::chrono::microseconds>(end_time - start_time);

                    // è®°å½•å¤„ç†å»¶è¿Ÿ
                    auto processing_duration = std::chrono::duration_cast<std::chrono::microseconds>(end_time - processing_start);
                    g_processing_latency.addSample(processing_duration.count());
                    g_metrics.avg_processing_latency_us.store(g_processing_latency.getAverageLatency());
                }

            } catch (const std::exception& e) {
                std::cerr << "âŒ ä¿å­˜FITSæ–‡ä»¶é”™è¯¯: " << e.what() << std::endl;
                g_metrics.file_write_errors++;
            }
        } else {
            std::this_thread::sleep_for(std::chrono::milliseconds(5));
        }
    }

    // ä¿å­˜å‰©ä½™æ•°æ®
    auto remainder = acc->getRemainderBatch();
    if (!remainder.empty()) {
        try {
            std::string filename = acc->generateFitsFileName();
            saveToFitsFileBatch(remainder, "./output_fits/" + filename);
        } catch (const std::exception& e) {
            std::cerr << "âŒ ä¿å­˜æœ€ç»ˆFITSæ–‡ä»¶é”™è¯¯: " << e.what() << std::endl;
            g_metrics.file_write_errors++;
        }
    }
}

// ==================== å¢å¼ºçš„æ•°æ®åŒ…è§£æçº¿ç¨‹ ====================
void parse_packet_header_thread(EnhancedPacketQueue& queue, std::atomic<bool>& running, DataAccumulator accumulators[4]) {
    TimestampedPacket packet({}, ip::udp::endpoint());

    while(running) {
        if(queue.pop(packet)) {
            try {
                auto processing_start = std::chrono::steady_clock::now();
                MyPacket myPacket(packet.data, packet.endpoint);
                HeaderInfo header = myPacket.getHeader();
                int index = header.multi_beam * 2 + header.polarization;
                accumulators[index].addPacket(myPacket);

                auto processing_end = std::chrono::steady_clock::now();
                auto processing_duration = std::chrono::duration_cast<std::chrono::microseconds>(processing_end - processing_start);
                g_processing_latency.addSample(processing_duration.count());

            } catch(const std::exception& e) {
                std::cerr << "âŒ æ•°æ®åŒ…å¤„ç†é”™è¯¯: " << e.what() << std::endl;
            }
        } else {
            std::this_thread::sleep_for(std::chrono::milliseconds(1));
        }
    }
}

// ==================== ä¸»å‡½æ•° ====================
// ä¿®æ”¹åçš„mainå‡½æ•°
int main() {
    try {
        std::cout << "ğŸš€ å¯åŠ¨å¤šGPUä¼˜åŒ–çš„å®æ—¶æ•°æ®å¤„ç†ç³»ç»Ÿ..." << std::endl;

        // é¦–å…ˆåˆå§‹åŒ–å¤šGPUç³»ç»Ÿ
        std::cout << "ğŸ”§ æ­£åœ¨åˆå§‹åŒ–å¤šGPUç³»ç»Ÿ..." << std::endl;
        if (!initialize_multi_gpu_system()) {
            std::cerr << "âŒ å¤šGPUç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥ï¼Œé€€å‡ºç¨‹åº" << std::endl;
            return 1;
        }

        // æ ¹æ®GPUæ•°é‡åŠ¨æ€è°ƒæ•´FFTçº¿ç¨‹æ•°
        int available_gpus = get_available_gpu_count();
        NUM_FFT_THREADS = available_gpus * OPTIMAL_FFT_THREADS_PER_GPU;

        std::cout << "âœ… å¤šGPUç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ" << std::endl;
        std::cout << "ğŸ® æ£€æµ‹åˆ° " << available_gpus << " ä¸ªå¯ç”¨GPU" << std::endl;
        std::cout << "âš™ï¸  FFTçº¿ç¨‹æ•°è°ƒæ•´ä¸º: " << NUM_FFT_THREADS << " (æ¯GPU " << OPTIMAL_FFT_THREADS_PER_GPU << " çº¿ç¨‹)" << std::endl;

        // è®¡ç®—ç†è®ºæ€§èƒ½æå‡
        double theoretical_speedup = available_gpus * 0.85; // è€ƒè™‘85%çš„å¹¶è¡Œæ•ˆç‡
        std::cout << "ğŸ“ˆ ç†è®ºæ€§èƒ½æå‡: " << std::fixed << std::setprecision(2) << theoretical_speedup << "x" << std::endl;

        OptimizedUDPServer server(PORT);

        DataAccumulator accumulators[4] = {
            DataAccumulator(false, 0),
            DataAccumulator(false, 1),
            DataAccumulator(true, 0),
            DataAccumulator(true, 1)
        };

        std::atomic<bool> running{true};
        std::vector<std::thread> workers;

        // æ•°æ®åŒ…è§£æçº¿ç¨‹æ•°é‡ä¿æŒä¸å˜
        for(int i = 0; i < NUM_THREADS; ++i) {
            workers.emplace_back(parse_packet_header_thread, std::ref(server.get_queue()), std::ref(running), accumulators);
        }

        // ä½¿ç”¨åŠ¨æ€è®¡ç®—çš„FFTçº¿ç¨‹æ•°é‡
        std::vector<std::thread> fft_threads;
        for(int i = 0; i < NUM_FFT_THREADS; ++i) {
            fft_threads.emplace_back(fft_thread_optimized, accumulators, std::ref(running), i);
        }

        // ä¿å­˜çº¿ç¨‹æ•°é‡ä¹Ÿç›¸åº”è°ƒæ•´
        std::vector<std::thread> save_threads;
        for(int i = 0; i < NUM_FFT_THREADS; ++i) {
            save_threads.emplace_back(save_thread_optimized_batch, accumulators, std::ref(running), i);
        }

        // ä½¿ç”¨å¤šGPUç‰ˆæœ¬çš„ç›‘æ§çº¿ç¨‹
        std::thread monitor(monitor_thread_enhanced_multigpu, std::ref(server), accumulators, std::ref(running));

        std::cout << "âœ… æ‰€æœ‰çº¿ç¨‹å·²å¯åŠ¨" << std::endl;
        std::cout << "   - ç½‘ç»œæ¥æ”¶çº¿ç¨‹: " << NUM_RECV_THREADS << std::endl;
        std::cout << "   - æ•°æ®åŒ…è§£æçº¿ç¨‹: " << NUM_THREADS << std::endl;
        std::cout << "   - FFTå¤„ç†çº¿ç¨‹: " << NUM_FFT_THREADS << " (åˆ†å¸ƒåœ¨ " << available_gpus << " ä¸ªGPUä¸Š)" << std::endl;
        std::cout << "   - ä¿å­˜çº¿ç¨‹: " << NUM_FFT_THREADS << std::endl;

        std::cout << "ğŸ“Š å¼€å§‹5ç§’åè¿›è¡Œç½‘ç»œæ€§èƒ½æµ‹è¯•..." << std::endl;

        // ç­‰å¾…5ç§’è®©ç³»ç»Ÿç¨³å®š
        std::this_thread::sleep_for(std::chrono::seconds(5));

        // æ‰§è¡Œç½‘ç»œæ€§èƒ½æµ‹è¯•
        server.performNetworkTest();

        std::cout << "ğŸ¯ å¤šGPUç³»ç»Ÿè¿è¡Œä¸­ï¼ŒæŒ‰å›è½¦é”®é€€å‡º..." << std::endl;
        std::cout << "ğŸ“ˆ é¢„æœŸæ€§èƒ½æå‡: " << theoretical_speedup << "x (åŸºäº " << available_gpus << " GPU)" << std::endl;
        std::cin.get();

        std::cout << "ğŸ”„ æ­£åœ¨åœæ­¢å¤šGPUç³»ç»Ÿ..." << std::endl;
        running = false;
        server.get_queue().stop();

        for(size_t i = 0; i < 4; ++i){
            accumulators[i].stop();
        }

        server.stop();

        for(auto& t : fft_threads) t.join();
        for(auto& t : save_threads) t.join();
        for(auto& t : workers) t.join();
        monitor.join();

        std::cout << "ğŸ“Š æœ€ç»ˆå¤šGPUæ€§èƒ½ç»Ÿè®¡:" << std::endl;
        g_metrics.printSummary();

        // æ‰“å°æœ€ç»ˆå¤šGPUç»Ÿè®¡
        print_multi_gpu_stats();

        std::cout << "âœ… å¤šGPUç³»ç»Ÿå·²å®‰å…¨åœæ­¢" << std::endl;

    } catch (std::exception& e) {
        std::cerr << "âŒ å¤šGPUç³»ç»Ÿå¼‚å¸¸: " << e.what() << std::endl;
        return 1;
    }

    return 0;
}